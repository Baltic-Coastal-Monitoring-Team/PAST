<img src="https://c5studio.pl/past/past-logo.png" width="450px">

# PAST – Perceptron as Similarity Transformation  
### A Machine Learning Approach for 3D Coordinate Frame Alignment

**PAST** is a Jupyter-based tool for learning three-dimensional similarity transformations between coordinate frames using a single-layer perceptron.  
The software reformulates the classical geodetic transformation into a transparent, gradient-based learning process, where perceptron weights directly represent rotation and scale, and biases represent translation.  
It serves both as a scientific and educational framework for analyzing coordinate transformations, noise propagation, and transformation stability under limited data availability.

---

## Key Features

- **Machine-learning-based transformation solver**  
  Learns 3D rotation, translation, and scale parameters using gradient descent (PyTorch backend).  
  Operates efficiently even with a small number of control points (e.g., 5 GCPs).

- **White-box architecture**  
  Full interpretability – perceptron weights map directly to geometric transformation coefficients.  
  All intermediate quantities (gradients, RMSE evolution, orthogonality checks) are explicitly accessible.

- **Integration with GeoPOINT**  
  Can directly process `.xlsx` files generated by **GeoPOINT**, using the `Original_Global` and `Transformed_Local` sheets.

- **Standalone mode**  
  Accepts any paired `.xlsx` or `.csv` datasets containing corresponding 3D coordinates.

- **Visualization and validation**  
  - RMSE convergence plot.  
  - Per-axis residual deviation bars (σx, σy, σz).  
  - 3D scatter comparison between predicted and reference coordinates.  
  - Optional educational appendix (1D perceptron learning analogy).

---

## Installation

The repository provides a ready-to-use **`environment.yml`** file for Conda.

```bash
# Clone the repository
git clone https://github.com/Baltic-Coastal-Monitoring-Team/PAST.git
cd PAST

# Create environment
conda env create -f environment.yml

# Activate environment
conda activate past
```

**Environment overview**

The Conda environment includes:
-	Python 3.11
-	numpy, pandas, matplotlib, seaborn
-	scipy, sympy, scikit-learn
-	openpyxl (Excel import/export)
-	jupyterlab
-	torch (PyTorch backend for gradient learning)


## Quick Start

1. Launch JupyterLab:

```bash
jupyter lab
```

2. Open the **`PAST.ipynb`** notebook.  
3. In Section 1. Paths & Parameters, define your input file(s):

Option A – GeoPOINT mode

```python
GEOPPOINT_WORKBOOK = "geopoint_data/synthetic_with_noise_coordinates.xlsx"
```
Option B – External mode
```python
EXTERNAL_LOCAL_PATH = "data/local_frame.csv"
EXTERNAL_FIXED_PATH = "data/global_frame.csv"
```

4. Adjust parameters:
```python
N_GCP = 5        # number of points used for training
MAX_ITERS = 2000 # max iterations
INIT_LR = 0.01   # initial learning rate
```

5.	Run all cells sequentially.
6.	The notebook will generate:
-	Rotation matrix (R) and translation vector (t)
-	Training and validation RMSE
-	Orthogonality and determinant tests
-	Visual plots (RMSE, residuals, 3D scatter)
-	Results export to output_data/results_past.csv and results_past.json

## Repository Structure

```
PAST/
├─ PAST.ipynb                 # main notebook
├─ environment.yml            # conda environment
├─ geopoint_data/             # sample input from GeoPOINT
│   └─ synthetic_with_noise_coordinates.xlsx
├─ output_data/               # generated results
│   ├─ results_past.csv
│   └─ results_past.json
└─ README.md                  # documentation
```

## Output Data Description

### `results_past.csv`

The file contains the main numerical results of the transformation learning process.  
Each row corresponds to one experiment or dataset processed in PAST.

| **Column** | **Description** |
|-------------|-----------------|
| `R11`, `R12`, `R13` | First row of the rotation matrix **R** |
| `R21`, `R22`, `R23` | Second row of **R** |
| `R31`, `R32`, `R33` | Third row of **R** |
| `tX`, `tY`, `tZ` | Components of the translation vector **t** |
| `detR` | Determinant of the rotation matrix (should be ≈ 1.0 for orthogonal rotation) |
| `train_sx`, `train_sy`, `train_sz` | RMSE values for training points (σx, σy, σz) |
| `valid_sx`, `valid_sy`, `valid_sz` | RMSE values for validation points (σx, σy, σz) |
| `mode` | Input mode: `GeoPOINT` or `External` |
| `n_total` | Total number of points in the dataset |
| `n_gcp` | Number of Ground Control Points (training subset) |
| `n_valid` | Number of validation points |

Example preview:

| R11 | R12 | R13 | R21 | R22 | R23 | R31 | R32 | R33 | tX | tY | tZ | detR | train_sx | train_sy | train_sz | valid_sx | valid_sy | valid_sz | mode | n_total | n_gcp | n_valid |
|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|
| 0.8066 | -0.5861 | 0.0783 | 0.5909 | 0.8030 | -0.0786 | -0.0168 | 0.1093 | 0.9937 | -2.37 | -13.79 | -2.92 | 0.99999 | 0.00295 | 0.01283 | 0.00040 | 0.01324 | 0.01687 | 0.01334 | GeoPOINT | 50 | 5 | 45 |

---

### `results_past.json`

A structured JSON report containing the complete output from the notebook, including:

- **Transformation parameters:**
  - Full 3 × 3 rotation matrix **R**
  - Translation vector **t**
- **Quality checks:**
  - Dot products between rotation matrix columns  
  - Norms of column vectors  
  - Determinant `detR`
- **RMSE diagnostics:**
  - Training and validation residuals (σx, σy, σz)
- **Run metadata:**
  - Input mode (`GeoPOINT` or `External`)
  - Number of total / training / validation points
  - Timestamp of execution

Example JSON snippet:

```json
{
  "mode": "GeoPOINT",
  "n_total": 50,
  "n_gcp": 5,
  "n_valid": 45,
  "R": [[0.8066, -0.5861, 0.0783],
        [0.5909, 0.8030, -0.0786],
        [-0.0168, 0.1093, 0.9937]],
  "t": [-2.37, -13.79, -2.92],
  "orthogonality": {
    "detR": 0.99999
  },
  "rmse": {
    "training": {"sx": 0.00295, "sy": 0.01283, "sz": 0.00040},
    "validation": {"sx": 0.01324, "sy": 0.01687, "sz": 0.01334}
  }
}
```

### Using the JSON output

The `results_past.json` file complements the CSV output by storing a **complete structured record** of each PAST run —  
including the full rotation and translation matrices, RMSE diagnostics, orthogonality checks, and metadata such as  
the number of points, input mode, and timestamp.

This file can be useful for:
- automatic aggregation of multiple experiments (batch processing),
- reproducibility and long-term result tracking,
- integration with other tools (e.g., Streamlit dashboards, COMPASS demonstrator),
- and for exporting transformation parameters to other Python or GIS environments.

Example of loading and inspecting the JSON file:

```python
import json

with open("output_data/results_past.json") as f:
    results = json.load(f)

print("Rotation matrix R:")
print(results["R"])
print("\nTranslation vector t:")
print(results["t"])
print("\nValidation RMSE:", results["rmse"]["validation"])
```

## Contributing

Contributions are welcome:  
- Bug fixes and improvements.  
- Additional error models or transformation options.  
- Examples of usage in geodetic or geospatial projects.  


## License

MIT License – see `LICENSE` file.


## Citation
Soon